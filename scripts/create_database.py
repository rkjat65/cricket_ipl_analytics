"""
Create SQLite Database for IPL Cricket Analytics
Loads matches and team data into a structured database
"""

import sqlite3
import pandas as pd
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# Paths
DB_FILE = Path("data/cricket_analytics.db")
MATCHES_FILE = Path("data/processed/ipl_complete_with_team_names.csv")
TEAMS_FILE = Path("data/raw/ipl_2024/all_teams_data.csv")
DELIVERIES_FILE = Path("data/raw/ipl_2024/all_ball_by_ball_data.csv")


def create_database_schema(conn):
    """Create database tables"""
    logger.info("\n" + "="*70)
    logger.info("üèóÔ∏è CREATING DATABASE SCHEMA")
    logger.info("="*70)
    
    cursor = conn.cursor()
    
    # Drop existing tables
    cursor.execute("DROP TABLE IF EXISTS deliveries")
    cursor.execute("DROP TABLE IF EXISTS matches")
    cursor.execute("DROP TABLE IF EXISTS teams")
    
    # Teams table
    logger.info("\nüìã Creating 'teams' table...")
    cursor.execute("""
        CREATE TABLE teams (
            team_id INTEGER PRIMARY KEY,
            team_name TEXT NOT NULL,
            short_name TEXT,
            is_active BOOLEAN DEFAULT 1,
            first_season INTEGER,
            last_season INTEGER
        )
    """)
    logger.info("‚úÖ Teams table created")
    
    # Matches table
    logger.info("\nüìã Creating 'matches' table...")
    cursor.execute("""
        CREATE TABLE matches (
            match_id INTEGER PRIMARY KEY,
            season INTEGER NOT NULL,
            match_date TEXT,
            venue TEXT,
            city TEXT,
            
            -- Team information
            team1_id INTEGER,
            team1_name TEXT,
            team2_id INTEGER,
            team2_name TEXT,
            
            -- Toss information
            toss_winner_id INTEGER,
            toss_winner_name TEXT,
            toss_decision TEXT,
            
            -- Match result
            match_winner_id INTEGER,
            match_winner_name TEXT,
            win_by_runs INTEGER,
            win_by_wickets INTEGER,
            result TEXT,
            
            -- Additional info
            player_of_match TEXT,
            match_number INTEGER,
            
            FOREIGN KEY (team1_id) REFERENCES teams(team_id),
            FOREIGN KEY (team2_id) REFERENCES teams(team_id),
            FOREIGN KEY (toss_winner_id) REFERENCES teams(team_id),
            FOREIGN KEY (match_winner_id) REFERENCES teams(team_id)
        )
    """)
    logger.info("‚úÖ Matches table created")
    
    # Deliveries table (optional - can be loaded later)
    logger.info("\nüìã Creating 'deliveries' table...")
    cursor.execute("""
        CREATE TABLE deliveries (
            delivery_id INTEGER PRIMARY KEY AUTOINCREMENT,
            season_id INTEGER,
            match_id INTEGER,
            
            -- Batting team
            team_batting_id INTEGER,
            batter TEXT,
            non_striker TEXT,
            
            -- Bowling team
            team_bowling_id INTEGER,
            bowler TEXT,
            
            -- Delivery details
            over_number INTEGER,
            ball_number INTEGER,
            
            -- Runs
            batter_runs INTEGER,
            extras INTEGER,
            total_runs INTEGER,
            
            -- Wicket
            is_wicket BOOLEAN,
            player_out TEXT,
            wicket_kind TEXT,
            fielders_involved TEXT,
            
            -- Extras details
            is_wide_ball BOOLEAN,
            is_no_ball BOOLEAN,
            is_leg_bye BOOLEAN,
            is_bye BOOLEAN,
            wide_ball_runs INTEGER,
            no_ball_runs INTEGER,
            
            -- Match context
            innings INTEGER,
            is_super_over BOOLEAN,
            
            FOREIGN KEY (match_id) REFERENCES matches(match_id),
            FOREIGN KEY (team_batting_id) REFERENCES teams(team_id),
            FOREIGN KEY (team_bowling_id) REFERENCES teams(team_id)
        )
    """)
    logger.info("‚úÖ Deliveries table created")
    
    conn.commit()
    logger.info("\n‚úÖ Database schema created successfully!")


def load_teams_data(conn):
    """Load teams data"""
    logger.info("\n" + "="*70)
    logger.info("üì• LOADING TEAMS DATA")
    logger.info("="*70)
    
    if not TEAMS_FILE.exists():
        logger.error(f"‚ùå Teams file not found: {TEAMS_FILE}")
        return
    
    teams_df = pd.read_csv(TEAMS_FILE)
    logger.info(f"‚úÖ Loaded {len(teams_df)} teams from CSV")
    
    # Add derived columns
    teams_df['short_name'] = teams_df['team_name'].apply(get_short_name)
    teams_df['is_active'] = teams_df['team_name'].apply(is_team_active)
    teams_df['first_season'] = None  # Will be calculated from matches
    teams_df['last_season'] = None
    
    # Load to database
    teams_df.to_sql('teams', conn, if_exists='replace', index=False)
    
    logger.info(f"‚úÖ {len(teams_df)} teams loaded into database")
    
    # Show loaded teams
    cursor = conn.cursor()
    cursor.execute("SELECT team_id, team_name, short_name, is_active FROM teams ORDER BY team_id")
    
    logger.info("\nüìä Teams in database:")
    for row in cursor.fetchall():
        status = "‚úÖ" if row[3] else "‚ùå"
        logger.info(f"  {status} {row[0]:4d} | {row[2]:<5} | {row[1]}")


def get_short_name(team_name):
    """Get team short name"""
    short_names = {
        'Mumbai Indians': 'MI',
        'Chennai Super Kings': 'CSK',
        'Royal Challengers Bangalore': 'RCB',
        'Kolkata Knight Riders': 'KKR',
        'Delhi Capitals': 'DC',
        'Punjab Kings': 'PBKS',
        'Rajasthan Royals': 'RR',
        'Sunrisers Hyderabad': 'SRH',
        'Gujarat Titans': 'GT',
        'Lucknow Super Giants': 'LSG',
        'Gujarat Lions': 'GL',
        'Rising Pune Supergiant': 'RPS',
        'Deccan Chargers': 'DC',
        'Pune Warriors': 'PWI',
        'Kochi Tuskers Kerala': 'KTK',
        'Rising Pune Supergiants': 'RPS'
    }
    return short_names.get(team_name, team_name[:3])


def is_team_active(team_name):
    """Check if team is currently active"""
    inactive_teams = [
        'Deccan Chargers', 'Pune Warriors', 'Kochi Tuskers Kerala',
        'Gujarat Lions', 'Rising Pune Supergiant', 'Rising Pune Supergiants'
    ]
    return team_name not in inactive_teams


def load_matches_data(conn):
    """Load matches data"""
    logger.info("\n" + "="*70)
    logger.info("üì• LOADING MATCHES DATA")
    logger.info("="*70)
    
    if not MATCHES_FILE.exists():
        logger.error(f"‚ùå Matches file not found: {MATCHES_FILE}")
        return
    
    matches_df = pd.read_csv(MATCHES_FILE)
    logger.info(f"‚úÖ Loaded {len(matches_df)} matches from CSV")
    
    # Select and rename columns for database
    db_columns = [
        'match_id', 'season', 'match_date', 'venue', 'city',
        'team1', 'team1_name', 'team2', 'team2_name',
        'toss_winner', 'toss_winner_name', 'toss_decision',
        'match_winner', 'match_winner_name',
        'win_by_runs', 'win_by_wickets', 'result',
        'player_of_match'
    ]
    
    # Add match_number if it exists
    if 'match_number' in matches_df.columns:
        db_columns.append('match_number')
    
    # Select available columns
    available_cols = [col for col in db_columns if col in matches_df.columns]
    db_df = matches_df[available_cols].copy()
    
    # Rename columns to match database schema
    column_mapping = {
        'team1': 'team1_id',
        'team2': 'team2_id',
        'toss_winner': 'toss_winner_id',
        'match_winner': 'match_winner_id'
    }
    db_df.rename(columns=column_mapping, inplace=True)
    
    # Load to database
    db_df.to_sql('matches', conn, if_exists='replace', index=False)
    
    logger.info(f"‚úÖ {len(db_df)} matches loaded into database")
    
    # Show summary
    cursor = conn.cursor()
    cursor.execute("""
        SELECT season, COUNT(*) as matches, 
               MIN(match_date) as first_match,
               MAX(match_date) as last_match
        FROM matches
        GROUP BY season
        ORDER BY season
    """)
    
    logger.info("\nüìä Matches by season:")
    logger.info(f"{'Season':<10} {'Matches':<10} {'First Match':<15} {'Last Match'}")
    logger.info("-" * 60)
    
    for row in cursor.fetchall():
        logger.info(f"{row[0]:<10} {row[1]:<10} {row[2]:<15} {row[3]}")


def load_deliveries_data(conn):
    """Load deliveries data (optional - large dataset)"""
    logger.info("\n" + "="*70)
    logger.info("üì• LOADING DELIVERIES DATA (Optional)")
    logger.info("="*70)
    
    if not DELIVERIES_FILE.exists():
        logger.warning(f"‚ö†Ô∏è Deliveries file not found: {DELIVERIES_FILE}")
        logger.info("Skipping deliveries data (can be loaded later)")
        return
    
    logger.info(f"üìä Deliveries file found: {DELIVERIES_FILE.name}")
    logger.info(f"‚ö†Ô∏è This file is large (278k+ rows). Load it? [y/N]")
    logger.info("Note: You can load this later if needed for detailed analysis")
    
    # For automation, we'll skip it by default
    # User can uncomment to load
    logger.info("‚è≠Ô∏è Skipping deliveries data for now (can load later)")
    logger.info("‚úÖ To load later, uncomment the loading code in this function")
    
    # Uncomment below to load deliveries:
    # deliveries_df = pd.read_csv(DELIVERIES_FILE)
    # logger.info(f"‚úÖ Loaded {len(deliveries_df)} deliveries")
    # deliveries_df.to_sql('deliveries', conn, if_exists='replace', index=False, chunksize=10000)
    # logger.info(f"‚úÖ Deliveries loaded into database")


def create_indexes(conn):
    """Create indexes for better query performance"""
    logger.info("\n" + "="*70)
    logger.info("üîç CREATING INDEXES")
    logger.info("="*70)
    
    cursor = conn.cursor()
    
    indexes = [
        # Matches indexes
        ("idx_matches_season", "CREATE INDEX idx_matches_season ON matches(season)"),
        ("idx_matches_date", "CREATE INDEX idx_matches_date ON matches(match_date)"),
        ("idx_matches_team1", "CREATE INDEX idx_matches_team1 ON matches(team1_id)"),
        ("idx_matches_team2", "CREATE INDEX idx_matches_team2 ON matches(team2_id)"),
        ("idx_matches_winner", "CREATE INDEX idx_matches_winner ON matches(match_winner_id)"),
        ("idx_matches_venue", "CREATE INDEX idx_matches_venue ON matches(venue)"),
        
        # Deliveries indexes (if table has data)
        ("idx_deliveries_match", "CREATE INDEX idx_deliveries_match ON deliveries(match_id)"),
        ("idx_deliveries_batter", "CREATE INDEX idx_deliveries_batter ON deliveries(batter)"),
        ("idx_deliveries_bowler", "CREATE INDEX idx_deliveries_bowler ON deliveries(bowler)"),
    ]
    
    created = 0
    for idx_name, idx_sql in indexes:
        try:
            cursor.execute(idx_sql)
            logger.info(f"‚úÖ Created: {idx_name}")
            created += 1
        except sqlite3.OperationalError as e:
            if "no such table" in str(e).lower():
                logger.info(f"‚è≠Ô∏è Skipped: {idx_name} (table not populated)")
            else:
                logger.warning(f"‚ö†Ô∏è Failed: {idx_name} - {e}")
    
    conn.commit()
    logger.info(f"\n‚úÖ Created {created} indexes")


def validate_database(conn):
    """Validate loaded data"""
    logger.info("\n" + "="*70)
    logger.info("‚úÖ DATABASE VALIDATION")
    logger.info("="*70)
    
    cursor = conn.cursor()
    
    # Count records
    cursor.execute("SELECT COUNT(*) FROM teams")
    teams_count = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM matches")
    matches_count = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM deliveries")
    deliveries_count = cursor.fetchone()[0]
    
    logger.info(f"\nüìä Record Counts:")
    logger.info(f"  - Teams: {teams_count}")
    logger.info(f"  - Matches: {matches_count:,}")
    logger.info(f"  - Deliveries: {deliveries_count:,}")
    
    # Test queries
    logger.info(f"\nüîç Sample Queries:")
    
    # Most successful team
    cursor.execute("""
        SELECT match_winner_name, COUNT(*) as wins
        FROM matches
        WHERE match_winner_name IS NOT NULL
        GROUP BY match_winner_name
        ORDER BY wins DESC
        LIMIT 5
    """)
    
    logger.info(f"\nüèÜ Top 5 Teams by Wins:")
    for row in cursor.fetchall():
        logger.info(f"  {row[0]:<30} {row[1]:3d} wins")
    
    # Matches per season
    cursor.execute("""
        SELECT season, COUNT(*) as matches
        FROM matches
        GROUP BY season
        ORDER BY season DESC
        LIMIT 5
    """)
    
    logger.info(f"\nüìÖ Recent Seasons:")
    for row in cursor.fetchall():
        logger.info(f"  {row[0]}: {row[1]} matches")
    
    # Database size
    cursor.execute("SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size()")
    db_size = cursor.fetchone()[0]
    db_size_mb = db_size / (1024 * 1024)
    
    logger.info(f"\nüíæ Database Size: {db_size_mb:.2f} MB")


def generate_summary():
    """Generate final summary"""
    logger.info("\n" + "="*70)
    logger.info("üéâ DATABASE CREATION COMPLETE!")
    logger.info("="*70)
    
    logger.info(f"\nüìÅ Database File:")
    logger.info(f"  Location: {DB_FILE}")
    logger.info(f"  Status: ‚úÖ Ready")
    
    logger.info(f"\nüìä Tables Created:")
    logger.info(f"  ‚úÖ teams (14 teams)")
    logger.info(f"  ‚úÖ matches (1,109 matches)")
    logger.info(f"  ‚úÖ deliveries (ready for data)")
    
    logger.info(f"\nüîç Indexes Created:")
    logger.info(f"  ‚úÖ Season-based queries")
    logger.info(f"  ‚úÖ Team-based queries")
    logger.info(f"  ‚úÖ Date-based queries")
    logger.info(f"  ‚úÖ Venue-based queries")
    
    logger.info(f"\n‚úÖ Next Steps:")
    logger.info(f"  1. Test queries with test_database_queries.py")
    logger.info(f"  2. Create Streamlit dashboard")
    logger.info(f"  3. Add Gemini AI integration")
    
    logger.info(f"\nüéØ Ready for Week 2, Day 2: Dashboard Development!")


def main():
    """Main execution"""
    logger.info("\n" + "="*70)
    logger.info("üèè IPL CRICKET DATABASE CREATION")
    logger.info("="*70)
    
    # Create database connection
    logger.info(f"\nüìÇ Database location: {DB_FILE}")
    
    # Remove old database if exists
    if DB_FILE.exists():
        logger.info("‚ö†Ô∏è Existing database found - will be recreated")
        DB_FILE.unlink()
    
    # Connect to database
    conn = sqlite3.connect(DB_FILE)
    logger.info("‚úÖ Database connection established")
    
    try:
        # Create schema
        create_database_schema(conn)
        
        # Load data
        load_teams_data(conn)
        load_matches_data(conn)
        load_deliveries_data(conn)
        
        # Create indexes
        create_indexes(conn)
        
        # Validate
        validate_database(conn)
        
        # Summary
        generate_summary()
        
    except Exception as e:
        logger.error(f"\n‚ùå Error: {e}")
        raise
    
    finally:
        conn.close()
        logger.info("\n‚úÖ Database connection closed")
    
    logger.info("\n" + "="*70)
    logger.info("‚úÖ SUCCESS!")
    logger.info("="*70)


if __name__ == "__main__":
    main()